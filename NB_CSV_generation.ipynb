{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import tvar, skew, kurtosis\n",
    "from scipy.integrate import simps\n",
    "\n",
    "from utils.dataloaders import OneSignal\n",
    "from utils import random_state\n",
    "# import random\n",
    "\n",
    "random_state(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureConstructor:\n",
    "    def __init__(self, data_name=None):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            --data_name: filename like 'S001_128.mat' or tuple (data_path,label_path,peaks_path)\n",
    "        \"\"\"\n",
    "        # Initialize class arguments\n",
    "        self.data_name = data_name\n",
    "\n",
    "        # Get information for patient with data_name\n",
    "        self.signal = OneSignal(data_name=self.data_name)\n",
    "        # Filter the PPG signal\n",
    "        self.signal.filter(fL = 0.5, fH = 4.3, order = 4)\n",
    "        # Align onsets to determine crops: always 1 peak between 2 onsets\n",
    "        self.signal.align_onsets()\n",
    "\n",
    "        # Set attributes of FeatureExtractor\n",
    "        self.ppg = self.signal.ppg              # get filtered ppg and derivatives\n",
    "        self.vpg = self.signal.vpg\n",
    "        self.apg = self.signal.apg\n",
    "        self.jpg = self.signal.jpg\n",
    "        self.fs = self.signal.fs                # sampling frequency                        --> int\n",
    "        self.peaks = self.signal.peaks.flatten()# peaks array                               --> (number_of_peaks,)\n",
    "        self.labels = self.signal.labels        # labels                                    --> (number_of_peaks,)\n",
    "        self.onsets = self.signal.on            # determined by self.signal.align_onsets()  --> (number_of_peaks+1,)\n",
    "\n",
    "\n",
    "    def generate_crops(self):\n",
    "        self.crops = []\n",
    "        while self.signal.indx < self.signal.indx_max:\n",
    "            # (x, y), (x_r, y_r) = self.signal.crop(raw=True)\n",
    "            crop, _ = self.signal.crop(raw=False)\n",
    "            self.crops.append(crop)\n",
    "\n",
    "    def get_intra_crop_features(self):\n",
    "        \"\"\n",
    "        self.ft_intra_crop_names = ['crop_duration','t_peak','mean','median','std','tvar','skew','kurt',\n",
    "                                    'auc','peak_amplitude','pulse_width','symmetry',]\n",
    "        self.ft_intra_crop = np.zeros(((self.peaks.shape[0]), len(self.ft_intra_crop_names)))\n",
    "\n",
    "        # Construct self.crops\n",
    "        self.generate_crops()\n",
    "\n",
    "        # Loop over all crops: extract features\n",
    "        for i, crop in enumerate(self.crops):\n",
    "            self.ft_intra_crop[i,:] = np.array(\n",
    "                [crop.shape[0] / self.fs,\n",
    "                 np.argmax(crop) / self.fs,\n",
    "                 np.mean(crop),\n",
    "                 np.median(crop),\n",
    "                 np.std(crop),\n",
    "                 tvar(crop), # tune values?\n",
    "                 skew(crop),\n",
    "                 kurtosis(crop),\n",
    "                 simps(np.abs(crop), dx=1/self.fs), # AUC: Simpson's rule for numeral integration\n",
    "                 np.max(crop)-np.min(crop),\n",
    "                 self.pulse_width(crop),\n",
    "                 self.symmetry_index(crop)\n",
    "                 ])\n",
    "\n",
    "    def get_inter_crop_features(self):\n",
    "        \"\"\n",
    "        self.ft_inter_crop_names = ['PTP','N_last_X_s']\n",
    "\n",
    "        self.ft_inter_crop = np.zeros(((self.peaks.shape[0]), len(self.ft_inter_crop_names)))\n",
    "        \n",
    "        self.ft_inter_crop[:,0] = self.peak_to_peak_times()\n",
    "        self.ft_inter_crop[:,1] = self.N_ratio()\n",
    "\n",
    "    def get_patient_specific_features(self):\n",
    "        \"\"\n",
    "        self.ft_patient_names = []\n",
    "        self.ft_patient = np.array([[]])\n",
    "\n",
    "    def construct_dataframe(self):\n",
    "        # Get features\n",
    "        self.feature_names = self.ft_intra_crop_names + self.ft_inter_crop_names + self.ft_patient_names\n",
    "        features = np.concatenate([self.ft_intra_crop, self.ft_inter_crop, self.ft_patient])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        data = {'peaks': self.peaks, 'labels': self.labels}\n",
    "        for i, feature_name in enumerate(self.feature_names):\n",
    "            data[feature_name] = features[:, i]\n",
    "\n",
    "        self.df = pd.DataFrame(data)\n",
    "        self.df.to_csv('your_dataframe.csv', index=False)\n",
    "\n",
    "    #---------------------------------------------------\n",
    "    #   Functions used in get_intra_crop_features()\n",
    "    #---------------------------------------------------\n",
    "        \n",
    "    def pulse_width(self, crop):\n",
    "        if len(crop) == 0:\n",
    "            return 0  # or some default value, as appropriate\n",
    "        \n",
    "        half_peak = max(crop) / 2\n",
    "        idx_peak = np.argmax(crop)\n",
    "        \n",
    "        # Find indices on both sides of the peak\n",
    "        # Index of half value of peak before peak\n",
    "        idx_t1 = self.find_nearest(crop[:idx_peak], half_peak)\n",
    "        # Index of half value of peak after peak\n",
    "        idx_t2 = self.find_nearest(crop[idx_peak:], half_peak) + idx_peak\n",
    "\n",
    "        # Calculate the width\n",
    "        width = (idx_t2 - idx_t1)/self.fs # [s]\n",
    "\n",
    "        return width\n",
    "\n",
    "    #From https://stackoverflow.com/questions/2566412/find-nearest-value-in-numpy-array\n",
    "    def find_nearest(self, array, value):\n",
    "        array = np.asarray(array)\n",
    "        if len(array) == 0:\n",
    "            idx = 0\n",
    "        else:\n",
    "            idx = (np.abs(array - value)).argmin()\n",
    "        return idx\n",
    "    \n",
    "    def symmetry_index(self, crop):\n",
    "        middle_idx = len(crop) // 2\n",
    "        \n",
    "        left_half = crop[:middle_idx]\n",
    "        right_half = crop[middle_idx:]\n",
    "        \n",
    "        mean_left = np.mean(left_half)\n",
    "        mean_right = np.mean(right_half)\n",
    "\n",
    "        symmetry_index = mean_right / mean_left\n",
    "        \n",
    "        return symmetry_index\n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    #   Functions used in get_inter_crop_features()\n",
    "    #---------------------------------------------------\n",
    "\n",
    "    def peak_to_peak_times(self):\n",
    "        time_between_peaks = np.diff(self.peaks) / self.fs\n",
    "        mean_PTP = np.mean(time_between_peaks)\n",
    "        time_between_peaks = mean_PTP\n",
    "        time_between_peaks = np.insert(time_between_peaks, 0, mean_PTP)\n",
    "\n",
    "        return time_between_peaks\n",
    "    \n",
    "    def N_ratio(self, time_window=20):\n",
    "        indices_before = int(time_window*self.fs)\n",
    "\n",
    "        number_of_Ns = np.zeros(len(self.peaks))\n",
    "        for i, peak_idx in enumerate(self.peaks):\n",
    "            indices_in_window = np.where((peak_idx - indices_before <= self.peaks) & (self.peaks < peak_idx))[0]\n",
    "            count = np.count_nonzero(self.labels[indices_in_window] ==  'N')\n",
    "            number_of_Ns[i] = count\n",
    "\n",
    "        return number_of_Ns\n",
    "        \n",
    "    # def drop_empty_crops(self, crops):\n",
    "\n",
    "    #     out = [crop for crop in crops if len(crop) > 4]\n",
    "    #     print(\"Number of crops eliminated: \", len(crops)-len(out))\n",
    "    #     return out\n",
    "\n",
    "    # def get_max_freq(self, crop, fs): #NEED FS OF INDIVIDUAL SIGNAL :(\n",
    "    #     fft = np.fft.fft(crop)\n",
    "    #     freqs = np.fft.fftfreq(len(crop), d=1/fs)\n",
    "    #     dom_freq_idx = np.argmax(np.abs(fft))\n",
    "    #     dom_freq = np.abs(freqs[dom_freq_idx])\n",
    "    #     return dom_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering signal S001_128.mat...\n"
     ]
    }
   ],
   "source": [
    "patient = FeatureConstructor('S001_128.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient.get_intra_crop_features()\n",
    "patient.get_inter_crop_features()\n",
    "patient.get_patient_specific_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 2603 and the array at index 2 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpatient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 78\u001b[0m, in \u001b[0;36mFeatureConstructor.construct_dataframe\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Get features\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mft_intra_crop_names \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mft_inter_crop_names \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mft_patient_names\n\u001b[1;32m---> 78\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mft_intra_crop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mft_inter_crop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mft_patient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeaks\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeaks, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels}\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 2603 and the array at index 2 has size 1"
     ]
    }
   ],
   "source": [
    "patient.construct_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [10 10 10 10]\n",
      "Distances with time: [0.1 0.1 0.1 0.1]\n",
      "Mean distance: 0.1\n",
      "Distances with mean at the beginning: [0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def P2P(peaks_idx, fs):\n",
    "    distances = np.diff(peaks_idx)\n",
    "    print(\"Distances:\", distances)\n",
    "\n",
    "    deltat = 1 / fs\n",
    "    distances = distances * deltat\n",
    "    print(\"Distances with time:\", distances)\n",
    "\n",
    "    mean_distance = np.mean(distances)\n",
    "    print(\"Mean distance:\", mean_distance)\n",
    "\n",
    "    distances = np.insert(distances, 0, mean_distance)\n",
    "    print(\"Distances with mean at the beginning:\", distances)\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Test variables\n",
    "peaks_idx_test = [10, 20, 30, 40, 50]  # Replace with your actual peaks_idx\n",
    "fs_test = 100  # Replace with your actual sampling frequency\n",
    "\n",
    "# Call the function with the test variables\n",
    "result = P2P(peaks_idx_test, fs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "class YourClass:\n",
    "    def __init__(self, peaks, fs):\n",
    "        self.peaks = peaks\n",
    "        self.fs = fs\n",
    "\n",
    "    def peak_to_peak_times(self):\n",
    "        time_between_peaks = np.diff(self.peaks) / self.fs\n",
    "        mean_PTP = np.mean(time_between_peaks)\n",
    "        time_between_peaks[0] = mean_PTP\n",
    "\n",
    "        return time_between_peaks\n",
    "\n",
    "# Test variables\n",
    "peaks_test = np.array([10, 20, 30, 40, 50])  # Replace with your actual peaks\n",
    "fs_test = 100  # Replace with your actual sampling frequency\n",
    "\n",
    "# Create an instance of YourClass\n",
    "test_instance = YourClass(peaks_test, fs_test)\n",
    "\n",
    "# Call the peak_to_peak_times method\n",
    "result = test_instance.peak_to_peak_times()\n",
    "\n",
    "# Print the result\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value): #From https://stackoverflow.com/questions/2566412/find-nearest-value-in-numpy-array, used for one of features\n",
    "    array = np.asarray(array)\n",
    "    if len(array) == 0:\n",
    "        idx = 0\n",
    "    else:\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def get_pulse_width(crop):  #need to verify if this done correctly...\n",
    "\n",
    "    half_peak = max(crop)/2\n",
    "    idx_peak = np.argmax(crop[1:])\n",
    "    idx_t1 = find_nearest(crop[:idx_peak], half_peak) #number of timesteps for amplitude to get to half value of peak before peak\n",
    "    idx_t1 = len(crop[:idx_peak]) -idx_t1 #time from that point to peak\n",
    "    idx_t2 = find_nearest(crop[idx_peak:], half_peak) #number of timesteps for amplitude to get to half value of peak after peak\n",
    "\n",
    "    return idx_t2+idx_t1 #time between half maximum values\n",
    "    \n",
    "def drop_empty_crops(crops):\n",
    "\n",
    "    out = [crop for crop in crops if len(crop) > 4]\n",
    "    print(\"Number of crops eliminated: \", len(crops)-len(out))\n",
    "    return out\n",
    "\n",
    "def get_max_freq(crop, fs): #NEED FS OF INDIVIDUAL SIGNAL :(\n",
    "    fft = np.fft.fft(crop)\n",
    "    freqs = np.fft.fftfreq(len(crop), d=1/fs)\n",
    "    dom_freq_idx = np.argmax(np.abs(fft))\n",
    "    dom_freq = np.abs(freqs[dom_freq_idx])\n",
    "    \n",
    "    return dom_freq\n",
    "\n",
    "def get_symmetry_index(crop): #\n",
    "    middle_idx = len(crop) // 2\n",
    "    \n",
    "    left_half = crop[:middle_idx]\n",
    "    right_half = crop[middle_idx:]\n",
    "    \n",
    "\n",
    "    mean_left = np.mean(left_half)\n",
    "    mean_right = np.mean(right_half)\n",
    "\n",
    "    symmetry_index = mean_right / mean_left\n",
    "    \n",
    "    return symmetry_index\n",
    "\n",
    "\n",
    "def crops2features(crops):\n",
    "\n",
    "    list_of_features = ['mean', 'median', 'std', 'var', 'skew', 'kurt','auc','peak_amplitude','pulse_width','max_freq','symmetry', 'peak_position']\n",
    "\n",
    "    ind = 0\n",
    "    df = pd.DataFrame(columns = list_of_features)\n",
    "    for crop in crops:\n",
    "\n",
    "        #First 6 features taken from Lab 1, rest inspired by ChatGPT\n",
    "        values = [np.mean(crop),\n",
    "                  np.median(crop),\n",
    "                  np.std(crop),\n",
    "                  stats.tvar(crop),\n",
    "                  stats.skew(crop),\n",
    "                  stats.kurtosis(crop),\n",
    "\n",
    "                    sum(np.array(crop)-min(crop)), #not sure if sound, since min could also be before or after crop...\n",
    "                    max(crop)-min(crop), #idem\n",
    "                    get_pulse_width(crop),\n",
    "                    get_max_freq(crop, 128), #assumed 128 for now....\n",
    "                    get_symmetry_index(crop),\n",
    "                    int(np.argmax(crop))\n",
    "                  ]\n",
    "\n",
    "        df2 = pd.DataFrame(dict(zip(list_of_features,\n",
    "                                    values)), index = [ind])\n",
    "        df = pd.concat([df,df2])\n",
    "        ind += 1\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering signal S001_128.mat...\n"
     ]
    }
   ],
   "source": [
    "patient = FeatureConstructor('S001_128.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2603,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient.peaks.shape\n",
    "# patient.labels.shape\n",
    "# patient.onsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
